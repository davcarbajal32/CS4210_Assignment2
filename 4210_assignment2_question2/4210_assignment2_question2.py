# -*- coding: utf-8 -*-
"""4210_assignment2_question2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S0QGrLjL5n6JYhzq5WbAe7c1ZDt7QQGa
"""

#-------------------------------------------------------------------------
# AUTHOR: David Carbajal
# FILENAME: 4210_assignment2_question2.ipynb
# SPECIFICATION:  training, testing, and output the performance of the 3 model
# FOR: CS 4210- Assignment #2
# TIME SPENT: 40 minutes
#-----------------------------------------------------------*/
#IMPORTANT NOTE: YOU ARE ALLOWED TO USE ANY PYTHON LIBRARY TO COMPLETE THIS PROGRAM
#Importing some Python libraries
from sklearn import tree
import pandas as pd
dataSets = ['contact_lens_training_1.csv', 'contact_lens_training_2.csv',
'contact_lens_training_3.csv']
num = 0
#Reading the test data in a csv file using pandas
dbTest = []
df_test = pd.read_csv('contact_lens_test.csv')
for _, row in df_test.iterrows():
  dbTest.append(row.tolist())
for ds in dataSets:
  dbTraining = []
  X = []
  Y = []

#Reading the training data in a csv file using pandas
# --> add your Python code here
  dbTraining = pd.read_csv(ds)

#Transform the original categorical training features to numbers and add to the 4D array X.
#For instance Young = 1, Prepresbyopic = 2, Presbyopic = 3, X = [[1, 1, 1, 1], [2, 2, 2, 2], ...]]
#--> add your Python code here
  age = {'Young': 1, 'Prepresbyopic': 2, 'Presbyopic': 3}
  spectacle = {'Myope': 1, 'Hypermetrope': 2}
  astigmatism = {'No': 1, 'Yes': 2}
  tear = {'Reduced': 1, 'Normal': 2}
  lenses = {'Yes': 1, 'No':  2}


  for _, row in dbTraining.iterrows():
    X.append([age[row["Age"]], spectacle[row["Spectacle Prescription"]], astigmatism[row["Astigmatism"]], tear[row["Tear Production Rate"]]])
#Transform the original categorical training classes to numbers and add to the vector Y.
#For instance Yes = 1 and No = 2, Y = [1, 1, 2, 2, ...]
#--> add your Python code here

  for _, row in dbTraining.iterrows():
    Y.append([lenses[row["Recommended Lenses"]]])

#Loop your training and test tasks 10 times here
  accuracy_values = []
  for i in range (10):
# fitting the decision tree to the data using entropy as your impurity measure and maximum depth = 5
# --> addd your Python code here
    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)
    clf = clf.fit(X, Y)
#Read the test data and add this data to dbTest
#--> add your Python code here
    correct_tests = 0
    total_tests = 0
    for data in dbTest:

#Transform the features of the test instances to numbers following the same strategy done during training,
#and then use the decision tree to make the class prediction. For instance: class_predicted = clf.predict([[3, 1, 2, 1]])[0]
#where [0] is used to get an integer as the predicted class label so that you can compare it with the true label
#--> add your Python code here
      x_test = [age[data[0]], spectacle[data[1]], astigmatism[data[2]], tear[data[3]],]
#Compare the prediction with the true label (located at data[4]) of the test instance to start calculating the accuracy.
#--> add your Python code here
      prediction = int(clf.predict([x_test])[0])
#Find the average of this model during the 10 runs (training and test set)
#--> add your Python code here
      if prediction == lenses[data[4]]:
        correct_tests += 1
      total_tests +=1

  accuracy = correct_tests / total_tests
  accuracy_values.append(accuracy)
  num += 1

#Print the average accuracy of this model during the 10 runs (training and testset).
#Your output should be something like that: final accuracy when training on contact_lens_training_1.csv: 0.2
#--> add your Python code here
  average_accuracy = sum(accuracy_values) / len(accuracy_values)
  print("average accuracy of data set ", num, " is equal to ", average_accuracy)
