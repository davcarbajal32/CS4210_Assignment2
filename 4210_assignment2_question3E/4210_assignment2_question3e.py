# -*- coding: utf-8 -*-
"""4210_assignment2_question3E.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DLzsRkYyps21OiokA-hLb_wsz6fWzS4S
"""

#-------------------------------------------------------------------------
# AUTHOR: David Carbajal
# FILENAME: 4210_assignment2_question3E.ipynb, email_classification.csv
# SPECIFICATION: computing the LOO-CV error rate for a 1NN classifier on the spam/ham classification task
# FOR: CS 4210- Assignment #2
# TIME SPENT: 30 minutes
#-----------------------------------------------------------*/
#IMPORTANT NOTE: YOU ARE ALLOWED TO USE ANY PYTHON LIBRARY TO COMPLETE THIS PROGRAM
#Importing some Python libraries
from sklearn.neighbors import KNeighborsClassifier
import pandas as pd
#Reading the data in a csv file using pandas
db = []
df = pd.read_csv('email_classification.csv')
for _, row in df.iterrows():
  db.append(row.tolist())

# Create a mapping from class labels to numbers
class_value = {'ham': 0, 'spam': 1}

total_errors = 0
total = 0

#Loop your data to allow each instance to be your test set
#Add the training features to the 20D array X removing the instance that will be used for testing in this iteration.
#For instance, X = [[1, 2, 3, 4, 5, ..., 20]].
#Convert each feature value to float to avoid warning messages
#--> add your Python code here
for row_num, i in enumerate(db):
  X = []
  for j, row in enumerate(db):
    if j == row_num:
        continue
    X.append([float(v) for v in row[:-1]])

#Transform the original training classes to numbers and add them to the vector Y.
#Do not forget to remove the instance that will be used for testing in this iteration.
#For instance, Y = [1, 2, ,...].
#Convert each feature value to float to avoid warning messages
#--> add your Python code here
  Y = []
  for j, row in enumerate(db):
    if j == row_num:
        continue
    Y.append(float(class_value[row[-1]]))

#Store the test sample of this iteration in the vector testSample
#--> add your Python code here
  testSample = []
  for v in i[:-1]:
    testSample.append(float(v))
#Fitting the knn to the data using k = 1 and Euclidean distance (L2 norm)
#--> add your Python code here
  clf = KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2)
  clf.fit(X, Y)
#Use your test sample in this iteration to make the class prediction. For instance:
#class_predicted = clf.predict([[1, 2, 3, 4, 5, ..., 20]])[0]
#--> add your Python code here
  class_predicted = clf.predict([testSample])[0]
#Compare the prediction with the true label of the test instance to startcalculating the error rate.
#--> add your Python code here

  if class_predicted != float(class_value[i[-1]]):
    total_errors += 1
  total += 1
#Print the error rate
#--> add your Python code here
print("LOO-CV error rate for a 1NN classifier is ", total_errors / total)
